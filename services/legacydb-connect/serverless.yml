service: legacydb-connect

frameworkVersion: "2"

package:
  individually: true

plugins:
  - serverless-bundle
  - serverless-dotenv-plugin
  - serverless-plugin-scripts
  - serverless-plugin-warmup
  - serverless-stack-termination-protection

provider:
  name: aws
  runtime: nodejs12.x
  region: us-east-1

custom:
  stage: ${opt:stage, self:provider.stage}
  region: ${opt:region, self:provider.region}
  iamPath: ${ssm:/configuration/${self:custom.stage}/iam/path~true, ssm:/configuration/default/iam/path~true, "/"}
  iamPermissionsBoundaryPolicy: ${ssm:/configuration/${self:custom.stage}/iam/permissionsBoundaryPolicy~true, ssm:/configuration/default/iam/permissionsBoundaryPolicy~true, ""}
  serverlessTerminationProtection:
    stages:
      - master
      - val
      - production
  infrastructureType: ${ssm:/configuration/${self:custom.stage}/infrastucture/type~true, ssm:/configuration/default/infrastucture/type~true, "development"}
  clusterArn: ${ssm:/kafka-cluster-${self:custom.stage}/clusterArn}
  bootstrapBrokerStringTls: ${ssm:/kafka-cluster-${self:custom.stage}/bootstrapBrokerStringTls}
  legacydbIp: ${ssm:/configuration/${self:custom.stage}/legacy-mssql/ip, ssm:/configuration/default/legacy-mssql/ip}
  legacydbPort: ${ssm:/configuration/${self:custom.stage}/legacy-mssql/port, ssm:/configuration/default/legacy-mssql/port}
  legacydbUser: ${ssm:/configuration/${self:custom.stage}/legacy-mssql/user, ssm:/configuration/default/legacy-mssql/user}
  legacydbPassword: ${ssm:/configuration/${self:custom.stage}/legacy-mssql/password, ssm:/configuration/default/legacy-mssql/password}
  vpcId: ${ssm:/configuration/${self:custom.stage}/vpc/id~true, ssm:/configuration/default/vpc/id~true}
  privateSubnets:
    - ${ssm:/configuration/${self:custom.stage}/vpc/subnets/private/a/id~true, ssm:/configuration/default/vpc/subnets/private/a/id~true}
    - ${ssm:/configuration/${self:custom.stage}/vpc/subnets/private/b/id~true, ssm:/configuration/default/vpc/subnets/private/b/id~true}
    - ${ssm:/configuration/${self:custom.stage}/vpc/subnets/private/c/id~true, ssm:/configuration/default/vpc/subnets/private/c/id~true}
  warmupEnabled:
    production: true
    development: false
  warmup:
    enabled: ${self:custom.warmupEnabled.${self:custom.infrastructureType}}
    role: LambdaWarmupRole
    vpc: false
    events:
      - schedule: rate(3 minutes)
    timeout: 20
    prewarm: true
    concurrency: 5
    folderName: node_modules/serverless-bundle/src/_warmup
    cleanFolder: false
  scripts:
    hooks:
      package:setupProviderConfiguration: |
        # Remove the timestamp line from the warmup handler so a new function is uploaded
        #   only if a configuration has truly changed.
        set -e
        if [ -d "node_modules/serverless-bundle/src/_warmup" ]; then
          cd node_modules/serverless-bundle/src/_warmup
          sed '/Generated/d' index.js > index.js.sub && mv -f index.js.sub index.js
        fi
      deploy:finalize: |
        serverless invoke --stage ${self:custom.stage} --function configureConnectors

functions:
  sinkMskToLegacydb:
    handler: handlers/sinkMskToLegacydb.handler
    role: LamdaSinkMsktoLegacydbRole
    environment:
      legacydbIp: ${self:custom.legacydbIp}
      legacydbPort: ${self:custom.legacydbPort}
      legacydbUser: ${self:custom.legacydbUser}
      legacydbPassword: ${self:custom.legacydbPassword}
    maximumRetryAttempts: 2
    vpc:
      securityGroupIds:
        - Ref: LambdaSinkMskToLegacydbSecurityGroup
      subnetIds: ${self:custom.privateSubnets}
  configureConnectors:
    handler: handlers/configureConnectors.handler
    role: LambdaConfigureConnectorsRole
    warmup:
      enabled: false
    environment:
      legacydbIp: ${self:custom.legacydbIp}
      legacydbPort: ${self:custom.legacydbPort}
      legacydbUser: ${self:custom.legacydbUser}
      legacydbPassword: ${self:custom.legacydbPassword}
      cluster: !Ref KafkaConnectCluster
      sinkTopics: aws.submission_portal.submissions.cdc.submission
      sinkFunctionArn: !GetAtt SinkMskToLegacydbLambdaFunction.Arn
      sinkFunctionRegion: ${self:custom.region}
    maximumRetryAttempts: 2
    timeout: 120
    vpc:
      securityGroupIds:
        - Ref: LambdaConfigureConnectorsSecurityGroup
      subnetIds: ${self:custom.privateSubnets}

resources:
  Conditions:
    CreatePermissionsBoundary:
      Fn::Not:
        - Fn::Equals:
            - ""
            - ${self:custom.iamPermissionsBoundaryPolicy}
  Resources:
    KafkaConnectWorkerLogGroup:
      Type: "AWS::Logs::LogGroup"
      Properties:
        LogGroupName: /aws/fargate/${self:service}-${self:custom.stage}-kafka-connect
    KafkaConnectWorkerSecurityGroup:
      Type: AWS::EC2::SecurityGroup
      Properties:
        GroupDescription: Security Group for the Fargate Connect Workers.
        VpcId: ${self:custom.vpcId}
    KafkaConnectWorkerSecurityGroupIngressLambda:
      Type: AWS::EC2::SecurityGroupIngress
      Properties:
        GroupId: !Sub "${KafkaConnectWorkerSecurityGroup}"
        IpProtocol: tcp
        FromPort: 8083
        ToPort: 8083
        SourceSecurityGroupId: !Sub "${LambdaConfigureConnectorsSecurityGroup}"
    KafkaConnectWorkerSecurityGroupIngressCluster:
      Type: AWS::EC2::SecurityGroupIngress
      Properties:
        GroupId: !Sub "${KafkaConnectWorkerSecurityGroup}"
        IpProtocol: tcp
        FromPort: 8083
        ToPort: 8083
        SourceSecurityGroupId: !Sub "${KafkaConnectWorkerSecurityGroup}"
    KafkaConnectWorkerRole:
      Type: "AWS::IAM::Role"
      Properties:
        AssumeRolePolicyDocument:
          Version: "2012-10-17"
          Statement:
            - Effect: "Allow"
              Principal:
                Service:
                  - "ecs.amazonaws.com"
                  - "ecs-tasks.amazonaws.com"
              Action: "sts:AssumeRole"
        Path: ${self:custom.iamPath}
        PermissionsBoundary:
          Fn::If:
            - CreatePermissionsBoundary
            - !Sub arn:aws:iam::${AWS::AccountId}:policy${self:custom.iamPermissionsBoundaryPolicy}
            - Ref: AWS::NoValue
        ManagedPolicyArns:
          - arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy
        Policies:
          - PolicyName: "LambdaRolePolicy"
            PolicyDocument:
              Version: "2012-10-17"
              Statement:
                - Effect: "Allow"
                  Action:
                    - "lambda:*"
                  Resource: !GetAtt SinkMskToLegacydbLambdaFunction.Arn
    KafkaConnectWorkerTaskDefinition:
      Type: "AWS::ECS::TaskDefinition"
      Properties:
        ContainerDefinitions:
          - Name: ${self:service}-${self:custom.stage}-worker
            Image: "confluentinc/cp-kafka-connect:5.2.4"
            Memory: 4096
            Cpu: 2048
            Command:
              - bash
              - "-c"
              - |
                export CONNECT_REST_HOST_NAME=`curl $ECS_CONTAINER_METADATA_URI_V4 | sed -e 's/.*IPv4Addresses":\["\(.*\)"\],"AttachmentIndex.*/\1/'` &&
                export CONNECT_REST_ADVERTISED_HOST_NAME=$CONNECT_REST_HOST_NAME &&
                curl -k -SL -o /etc/kafka-connect/jars/kafka-connect-lambda-1.2.2.jar "https://github.com/Nordstrom/kafka-connect-lambda/releases/download/v1.2.2/kafka-connect-lambda-1.2.2.jar" &&
                curl -k -SL "https://download.microsoft.com/download/f/c/d/fcd3f599-2d60-46c1-8628-45c2eff1b207/sqljdbc_8.4.1.0_deu.tar.gz" | \
                tar -xzf - -C /etc/kafka-connect/jars --strip-components=2 sqljdbc_8.4/deu/mssql-jdbc-8.4.1.jre8.jar &&
                /etc/confluent/docker/run
            Environment:
              - Name: CONNECT_BOOTSTRAP_SERVERS
                Value: >-
                  ${self:custom.bootstrapBrokerStringTls}
              - Name: CONNECT_GROUP_ID
                Value: mgmt.connect.${self:service}-${self:custom.stage}
              - Name: CONNECT_CONFIG_STORAGE_TOPIC
                Value: mgmt.connect.${self:service}-${self:custom.stage}.config
              - Name: CONNECT_OFFSET_STORAGE_TOPIC
                Value: mgmt.connect.${self:service}-${self:custom.stage}.offsets
              - Name: CONNECT_STATUS_STORAGE_TOPIC
                Value: mgmt.connect.${self:service}-${self:custom.stage}.status
              - Name: CONNECT_KEY_CONVERTER
                Value: org.apache.kafka.connect.json.JsonConverter
              - Name: CONNECT_VALUE_CONVERTER
                Value: org.apache.kafka.connect.json.JsonConverter
              - Name: CONNECT_INTERNAL_KEY_CONVERTER
                Value: org.apache.kafka.connect.json.JsonConverter
              - Name: CONNECT_INTERNAL_VALUE_CONVERTER
                Value: org.apache.kafka.connect.json.JsonConverter
              - Name: CONNECT_PLUGIN_PATH
                Value: /usr/share/java,/etc/kafka-connect/jars
              - Name: CONNECT_SECURITY_PROTOCOL
                Value: SSL
              # Producer/Consumer configs below
              # Thank you to https://github.com/confluentinc/kafka-connect-jdbc/issues/161
              - Name: CONNECT_PRODUCER_BOOTSTRAP_SERVERS
                Value: >-
                  ${self:custom.bootstrapBrokerStringTls}
              - Name: CONNECT_PRODUCER_SECURITY_PROTOCOL
                Value: SSL
              - Name: CONNECT_CONSUMER_BOOTSTRAP_SERVERS
                Value: >-
                  ${self:custom.bootstrapBrokerStringTls}
              - Name: CONNECT_CONSUMER_SECURITY_PROTOCOL
                Value: SSL
            LogConfiguration:
              LogDriver: awslogs
              Options:
                awslogs-region: !Sub "${AWS::Region}"
                awslogs-group: !Sub "${KafkaConnectWorkerLogGroup}"
                awslogs-stream-prefix: fargate
        Family: ${self:service}-${self:custom.stage}-kafka-connect-worker
        NetworkMode: awsvpc
        ExecutionRoleArn: !GetAtt KafkaConnectWorkerRole.Arn
        TaskRoleArn: !GetAtt KafkaConnectWorkerRole.Arn
        RequiresCompatibilities:
          - FARGATE
        Memory: 4GB
        Cpu: 2048
    KafkaConnectCluster:
      Type: "AWS::ECS::Cluster"
    KafkaConnectService:
      Type: "AWS::ECS::Service"
      Properties:
        Cluster: !Sub "${KafkaConnectCluster}"
        DeploymentConfiguration:
          MaximumPercent: 100
          MinimumHealthyPercent: 0
        LaunchType: FARGATE
        ServiceName: kafka-connect
        DesiredCount: 1
        TaskDefinition: !Sub "${KafkaConnectWorkerTaskDefinition}"
        NetworkConfiguration:
          AwsvpcConfiguration:
            AssignPublicIp: DISABLED
            SecurityGroups:
              - !Sub "${KafkaConnectWorkerSecurityGroup}"
            Subnets: ${self:custom.privateSubnets}
    LambdaConfigureConnectorsSecurityGroup:
      Type: AWS::EC2::SecurityGroup
      Properties:
        GroupDescription: Security Group for configuring the connector.
        VpcId: ${self:custom.vpcId}
    LambdaSinkMskToLegacydbSecurityGroup:
      Type: AWS::EC2::SecurityGroup
      Properties:
        GroupDescription: Security Group for LegacyDB sink function.
        VpcId: ${self:custom.vpcId}
    LamdaSinkMsktoLegacydbRole:
      Type: "AWS::IAM::Role"
      Properties:
        AssumeRolePolicyDocument:
          Version: "2012-10-17"
          Statement:
            - Effect: "Allow"
              Principal:
                Service: "lambda.amazonaws.com"
              Action: "sts:AssumeRole"
        Path: ${self:custom.iamPath}
        PermissionsBoundary:
          Fn::If:
            - CreatePermissionsBoundary
            - !Sub arn:aws:iam::${AWS::AccountId}:policy${self:custom.iamPermissionsBoundaryPolicy}
            - Ref: AWS::NoValue
        Policies:
          - PolicyName: "LambdaRolePolicy"
            PolicyDocument:
              Version: "2012-10-17"
              Statement:
                - Effect: "Allow"
                  Action:
                    - logs:CreateLogGroup
                    - logs:CreateLogStream
                    - logs:PutLogEvents
                  Resource: "arn:aws:logs:*:*:*"
                - Effect: "Allow"
                  Action:
                    - ec2:CreateNetworkInterface
                    - ec2:DeleteNetworkInterface
                    - ec2:DetachNetworkInterface
                    - ec2:DescribeNetworkInterfaces
                    - ec2:DescribeSecurityGroups
                    - ec2:DescribeSubnets
                    - ec2:DescribeVpcs
                  Resource: "*"
                - Effect: "Allow"
                  Action:
                    - kafka:DescribeCluster
                    - kafka:GetBootstrapBrokers
                  Resource: ${self:custom.clusterArn}
    LambdaConfigureConnectorsRole:
      Type: "AWS::IAM::Role"
      Properties:
        AssumeRolePolicyDocument:
          Version: "2012-10-17"
          Statement:
            - Effect: "Allow"
              Principal:
                Service: "lambda.amazonaws.com"
              Action: "sts:AssumeRole"
        Path: ${self:custom.iamPath}
        PermissionsBoundary:
          Fn::If:
            - CreatePermissionsBoundary
            - !Sub arn:aws:iam::${AWS::AccountId}:policy${self:custom.iamPermissionsBoundaryPolicy}
            - Ref: AWS::NoValue
        Policies:
          - PolicyName: "LambdaRolePolicy"
            PolicyDocument:
              Version: "2012-10-17"
              Statement:
                - Effect: "Allow"
                  Action:
                    - logs:CreateLogGroup
                    - logs:CreateLogStream
                    - logs:PutLogEvents
                  Resource: "arn:aws:logs:*:*:*"
                - Effect: "Allow"
                  Action:
                    - ec2:CreateNetworkInterface
                    - ec2:DeleteNetworkInterface
                    - ec2:DetachNetworkInterface
                    - ec2:DescribeNetworkInterfaces
                    - ec2:DescribeSecurityGroups
                    - ec2:DescribeSubnets
                    - ec2:DescribeVpcs
                  Resource: "*"
                - Effect: "Allow"
                  Action:
                    - kafka:DescribeCluster
                    - kafka:GetBootstrapBrokers
                  Resource: ${self:custom.clusterArn}
                - Effect: "Allow"
                  Action:
                    - ecs:ListTasks
                    - ecs:DescribeTasks
                  Resource: "*"
    LambdaWarmupRole:
      Type: "AWS::IAM::Role"
      Properties:
        AssumeRolePolicyDocument:
          Version: "2012-10-17"
          Statement:
            - Effect: "Allow"
              Principal:
                Service: "lambda.amazonaws.com"
              Action: "sts:AssumeRole"
        Path: ${self:custom.iamPath}
        PermissionsBoundary:
          Fn::If:
            - CreatePermissionsBoundary
            - !Sub arn:aws:iam::${AWS::AccountId}:policy${self:custom.iamPermissionsBoundaryPolicy}
            - Ref: AWS::NoValue
        Policies:
          - PolicyName: "Warmup"
            PolicyDocument:
              Version: "2012-10-17"
              Statement:
                - Effect: "Allow"
                  Action:
                    - logs:CreateLogGroup
                    - logs:CreateLogStream
                    - logs:PutLogEvents
                  Resource: "arn:aws:logs:*:*:*"
                - Effect: "Allow"
                  Action:
                    - lambda:InvokeFunction
                  Resource: "*"
  Outputs:
    KafkaConnectWorkerSecurityGroupId:
      Description: |
        The ID of the security group attached to the Kafka Connect cluster tasks.
        This can be used by other resources to attach additional ingress rules.
      Value: !Ref KafkaConnectWorkerSecurityGroup
